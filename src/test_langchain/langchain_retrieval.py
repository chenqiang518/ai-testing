#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
# æå‰è®¾ç½® UA
os.environ["USER_AGENT"] = "MyLangChainBot/1.0"

import time
from math import ceil
from pathlib import Path
from uuid import uuid4
import faiss

from langchain_community.document_loaders import SitemapLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import create_retrieval_chain

# å¼•å…¥ä½ çš„åµŒå…¥æ¨¡å‹å’Œå¤§æ¨¡å‹
from src.ai_model.qwen_embedding import qwen_embeddings
from src.ai_model.qwen_model import qwen_model

# å‘é‡åº“å­˜å‚¨ç›®å½•
INDEX_DIR = Path("faiss_index")
batch_size = 10

if INDEX_DIR.exists():
    print(f"ğŸ“‚ æ£€æµ‹åˆ°å·²æœ‰å‘é‡åº“: {INDEX_DIR}ï¼Œç›´æ¥åŠ è½½...")
    start_time = time.time()
    vector = FAISS.load_local(
        folder_path=str(INDEX_DIR),
        embeddings=qwen_embeddings,
        allow_dangerous_deserialization=True
    )
    print(f"âœ… å‘é‡åº“åŠ è½½å®Œæˆï¼Œç”¨æ—¶ {time.time() - start_time:.2f} ç§’")
else:
    print("ğŸ“­ æœªå‘ç°å·²æœ‰å‘é‡åº“ï¼Œå¼€å§‹æŠ“å– + æ„å»º...")

    # 1. æŠ“å–æ•°æ®
    print("ğŸ” æŠ“å– sitemap ä¸­çš„é¡µé¢ï¼Œè¯·ç¨å€™...")
    loader = SitemapLoader("https://docs.langchain.com/sitemap.xml")
    docs = loader.load()
    print(f"âœ… æŠ“å–å®Œæˆï¼Œé¡µé¢æ€»æ•°: {len(docs)}")

    # 2. æ–‡æ¡£åˆ‡åˆ†
    print("âœ‚ï¸ æ­£åœ¨åˆ‡åˆ†æ–‡æ¡£...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    documents = text_splitter.split_documents(docs)
    print(f"âœ… åˆ‡åˆ†å®Œæˆï¼Œæ€» chunk æ•°é‡: {len(documents)}")

    # 3. åˆ›å»ºä¸€ä¸ªç©º FAISSï¼ˆé‡è¦ä¿®å¤ï¼‰
    embedding_dim = len(qwen_embeddings.embed_query("test"))
    index = faiss.IndexFlatL2(embedding_dim)
    vector = FAISS(
        embedding_function=qwen_embeddings,
        index=index,
        docstore=InMemoryDocstore(),
        index_to_docstore_id={}
    )

    # 4. åˆ†æ‰¹æ·»åŠ æ–‡æ¡£
    total_batches = ceil(len(documents) / batch_size)
    print(f"ğŸš€ å¼€å§‹å‘é‡åŒ–å¹¶å­˜å‚¨åˆ° FAISSï¼Œæ¯æ‰¹ {batch_size} æ¡ï¼Œæ€»æ‰¹æ¬¡ {total_batches}...")

    start_time = time.time()
    for i in range(0, len(documents), batch_size):
        batch = documents[i:i+batch_size]
        vector.add_documents(batch)
        print(f"  ğŸ“ å·²å¤„ç†æ‰¹æ¬¡ {i // batch_size + 1} / {total_batches}")
    print(f"âœ… å‘é‡åŒ–å®Œæˆï¼Œæ€»ç”¨æ—¶ {time.time() - start_time:.2f} ç§’")

    # 5. ä¿å­˜å‘é‡åº“
    print(f"ğŸ’¾ ä¿å­˜å‘é‡åº“åˆ° {INDEX_DIR} ...")
    vector.save_local(str(INDEX_DIR))
    print("âœ… å‘é‡åº“ä¿å­˜å®Œæˆ")

# 6. åˆ›å»ºæ£€ç´¢é—®ç­”é“¾
prompt = ChatPromptTemplate.from_template("""
Answer the following question based only on the provided context:
<context>
{context}
</context>
Question: {input}
""".strip())

llm = qwen_model
document_chain = create_stuff_documents_chain(llm, prompt)
retriever = vector.as_retriever()
retrieval_chain = create_retrieval_chain(retriever, document_chain)

# 7. æµ‹è¯•
question = "how can langsmith help with testing?"
print(f"\nâ“ æé—®: {question}")
response = retrieval_chain.invoke({"input": question})

print("\nğŸ¤– å›ç­”ï¼š")
print(response["answer"])
